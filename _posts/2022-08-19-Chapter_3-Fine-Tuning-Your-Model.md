---
keywords: fastai
description: Chapter 3 - How good is your model?
title: Supervised Learning with scikit-learn - Part 3
toc: true
branch: master
badges: true
comments: true
author: Hai Nguyen
categories: [Datacamp, Machine Learning, Supervised Learning, Python, Classification, Overfitting, Underfitting, scikit-learn]
image: images/supervised_learning_p3.png
hide: false
search_exclude: true
metadata_key1: metadata_value1
metadata_key2: metadata_value2
nb_path: _notebooks/Supervised Learning with scikit-learn/2022-08-19-Chapter_3 Fine-Tuning Your Model.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/Supervised Learning with scikit-learn/2022-08-19-Chapter_3 Fine-Tuning Your Model.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://github.com/anhhaibkhn/Data-Science-selfstudy-notes-Blog/tree/master/_notebooks/Supervised%20Learning%20with%20scikit-learn"><strong>Download Datasets and Presentation slides for this post HERE</strong></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>Having trained models, now you will learn how to evaluate them. In this chapter, you will be introduced to several metrics along with a visualization technique for analyzing classification model performance using scikit-learn. You will also learn how to optimize classification and regression models through the use of hyperparameter tuning.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.expand_frame_repr&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-good-is-your-model?">How good is your model?<a class="anchor-link" href="#How-good-is-your-model?"> </a></h2><p>Classification metrics</p>
<ul>
<li>Measuring model performance with accuracy:</li>
<li>Fraction of correctly classified samples</li>
<li>Not always a useful metric</li>
</ul>
<p>Class imbalance</p>
<ul>
<li><p>Classi,cation for predicting fraudulent bank transactions</p>
<ul>
<li>99% of transactions are legitimate; 1% are fraudulent</li>
</ul>
</li>
<li><p>Could build a classi,er that predicts NONE of the transactions are fraudulent</p>
<ul>
<li>99% accurate!</li>
<li>But terrible at actually predicting fraudulent transactions</li>
<li>Fails at its original purpose</li>
</ul>
</li>
<li><p>Class imbalance: Uneven frequency of classes</p>
</li>
<li>Need a different way to assess performance</li>
</ul>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/metrics1.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/metrics2.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/metrics3.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/metrics4.png" alt=""></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">churn_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/telecom_churn_clean.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">churn_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">churn_df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">churn_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;churn&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">churn_df</span><span class="p">[</span><span class="s2">&quot;churn&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>account_length</th>
      <th>area_code</th>
      <th>international_plan</th>
      <th>voice_mail_plan</th>
      <th>number_vmail_messages</th>
      <th>total_day_minutes</th>
      <th>total_day_calls</th>
      <th>total_day_charge</th>
      <th>total_eve_minutes</th>
      <th>total_eve_calls</th>
      <th>total_eve_charge</th>
      <th>total_night_minutes</th>
      <th>total_night_calls</th>
      <th>total_night_charge</th>
      <th>total_intl_minutes</th>
      <th>total_intl_calls</th>
      <th>total_intl_charge</th>
      <th>customer_service_calls</th>
      <th>churn</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>128</td>
      <td>415</td>
      <td>0</td>
      <td>1</td>
      <td>25</td>
      <td>265.1</td>
      <td>110</td>
      <td>45.07</td>
      <td>197.4</td>
      <td>99</td>
      <td>16.78</td>
      <td>244.7</td>
      <td>91</td>
      <td>11.01</td>
      <td>10.0</td>
      <td>3</td>
      <td>2.70</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>107</td>
      <td>415</td>
      <td>0</td>
      <td>1</td>
      <td>26</td>
      <td>161.6</td>
      <td>123</td>
      <td>27.47</td>
      <td>195.5</td>
      <td>103</td>
      <td>16.62</td>
      <td>254.4</td>
      <td>103</td>
      <td>11.45</td>
      <td>13.7</td>
      <td>3</td>
      <td>3.70</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>137</td>
      <td>415</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>243.4</td>
      <td>114</td>
      <td>41.38</td>
      <td>121.2</td>
      <td>110</td>
      <td>10.30</td>
      <td>162.6</td>
      <td>104</td>
      <td>7.32</td>
      <td>12.2</td>
      <td>5</td>
      <td>3.29</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84</td>
      <td>408</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>299.4</td>
      <td>71</td>
      <td>50.90</td>
      <td>61.9</td>
      <td>88</td>
      <td>5.26</td>
      <td>196.9</td>
      <td>89</td>
      <td>8.86</td>
      <td>6.6</td>
      <td>7</td>
      <td>1.78</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>75</td>
      <td>415</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>166.7</td>
      <td>113</td>
      <td>28.34</td>
      <td>148.3</td>
      <td>122</td>
      <td>12.61</td>
      <td>186.9</td>
      <td>121</td>
      <td>8.41</td>
      <td>10.1</td>
      <td>3</td>
      <td>2.73</td>
      <td>3</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 3333 entries, 0 to 3332
Data columns (total 19 columns):
 #   Column                  Non-Null Count  Dtype  
---  ------                  --------------  -----  
 0   account_length          3333 non-null   int64  
 1   area_code               3333 non-null   int64  
 2   international_plan      3333 non-null   int64  
 3   voice_mail_plan         3333 non-null   int64  
 4   number_vmail_messages   3333 non-null   int64  
 5   total_day_minutes       3333 non-null   float64
 6   total_day_calls         3333 non-null   int64  
 7   total_day_charge        3333 non-null   float64
 8   total_eve_minutes       3333 non-null   float64
 9   total_eve_calls         3333 non-null   int64  
 10  total_eve_charge        3333 non-null   float64
 11  total_night_minutes     3333 non-null   float64
 12  total_night_calls       3333 non-null   int64  
 13  total_night_charge      3333 non-null   float64
 14  total_intl_minutes      3333 non-null   float64
 15  total_intl_calls        3333 non-null   int64  
 16  total_intl_charge       3333 non-null   float64
 17  customer_service_calls  3333 non-null   int64  
 18  churn                   3333 non-null   int64  
dtypes: float64(8), int64(11)
memory usage: 520.8 KB
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea ">
<pre>None</pre>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(3333, 18) (3333,)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>


<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(1999, 18) (1999,)
[[1126   12]
 [ 158   38]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.88      0.99      0.93      1138
           1       0.76      0.19      0.31       196

    accuracy                           0.87      1334
   macro avg       0.82      0.59      0.62      1334
weighted avg       0.86      0.87      0.84      1334

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Deciding-on-a-primary-metric">Deciding on a primary metric<a class="anchor-link" href="#Deciding-on-a-primary-metric"> </a></h3><p>Deciding on a primary metric
As you have seen, several metrics can be useful to evaluate the performance of classification models, including accuracy, precision, recall, and F1-score.</p>
<p>In this exercise, you will be provided with three different classification problems, and your task is to select the problem where precision is best suited as the primary metric.</p>
<blockquote><p>Answer:A model predicting if a customer is a high-value lead for a sales team with limited capacity.
With limited capacity, the sales team needs the model to return the highest proportion of true positives compared to all predicted positives, thus minimizing wasted effort.</p>
</blockquote>
<h3 id="Assessing-a-diabetes-prediction-classifier">Assessing a diabetes prediction classifier<a class="anchor-link" href="#Assessing-a-diabetes-prediction-classifier"> </a></h3><p>In this chapter you'll work with the diabetes_df dataset introduced previously.</p>
<p>The goal is to predict whether or not each individual is likely to have diabetes based on the features body mass index (BMI) and age (in years). Therefore, it is a binary classification problem. A target value of 0 indicates that the individual does not have diabetes, while a value of 1 indicates that the individual does have diabetes.</p>
<p>diabetes_df has been preloaded for you as a pandas DataFrame and split into X_train, X_test, y_train, and y_test. In addition, a KNeighborsClassifier() has been instantiated and assigned to knn.</p>
<p>You will fit the model, make predictions on the test set, then produce a confusion matrix and classification report.</p>
<p>Instructions:</p>
<ul>
<li>Import confusion_matrix and classification_report.</li>
<li>Fit the model to the training data.</li>
<li>Predict the labels of the test set, storing the results as y_pred.</li>
<li>Compute and print the confusion matrix and classification report for the test labels versus the predicted labels.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/diabetes_clean.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># diabetes_df = df.loc[(df[&#39;glucose&#39;] != 0) &amp; (df[&#39;bmi&#39;] != 0)].copy()</span>
<span class="n">diabetes_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="p">[[</span><span class="s2">&quot;bmi&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="p">[</span><span class="s2">&quot;diabetes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pregnancies</th>
      <th>glucose</th>
      <th>diastolic</th>
      <th>triceps</th>
      <th>insulin</th>
      <th>bmi</th>
      <th>dpf</th>
      <th>age</th>
      <th>diabetes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>148</td>
      <td>72</td>
      <td>35</td>
      <td>0</td>
      <td>33.6</td>
      <td>0.627</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>85</td>
      <td>66</td>
      <td>29</td>
      <td>0</td>
      <td>26.6</td>
      <td>0.351</td>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>183</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>23.3</td>
      <td>0.672</td>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>89</td>
      <td>66</td>
      <td>23</td>
      <td>94</td>
      <td>28.1</td>
      <td>0.167</td>
      <td>21</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>137</td>
      <td>40</td>
      <td>35</td>
      <td>168</td>
      <td>43.1</td>
      <td>2.288</td>
      <td>33</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(537, 2) (537,)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="c1"># Fit the model to the training data</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict the labels of the test data: y_pred</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Generate the confusion matrix and classification report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[116  35]
 [ 47  33]]
              precision    recall  f1-score   support

           0       0.71      0.77      0.74       151
           1       0.49      0.41      0.45        80

    accuracy                           0.65       231
   macro avg       0.60      0.59      0.59       231
weighted avg       0.63      0.65      0.64       231

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The model produced 116  true positives, 33 true negatives, 35 false negatives, and 47 false positives. The classification report shows a better F1-score for the zero class, which represents individuals who do not have diabetes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Logistic-regression-and-the-ROC-curve">Logistic regression and the ROC curve<a class="anchor-link" href="#Logistic-regression-and-the-ROC-curve"> </a></h2><p>Logistic regression for binary classification</p>
<ul>
<li>Logistic regression is used for classi,cation problems</li>
<li>Logistic regression outputs probabilities</li>
<li>If the probability, p &gt; 0.5:<ul>
<li>The data is labeled 1</li>
</ul>
</li>
<li>If the probability, p &lt; 0.5:<ul>
<li>The data is labeled 0</li>
</ul>
</li>
</ul>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/logreg1.png" alt=""></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">churn_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;churn&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">churn_df</span><span class="p">[</span><span class="s2">&quot;churn&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Predicting probabilities</span>
<span class="n">y_pred_probs</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.21454950701430497
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Probability thresholds</p>
<ul>
<li>By default, logistic regression threshold = 0.5</li>
<li>Not speci,c to logistic regression<ul>
<li>KNN classi,ers also have thresholds</li>
</ul>
</li>
<li>What happens if we vary the threshold?</li>
</ul>
<p>ROC curve</p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/roc_curve.png" alt=""></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Logistic Regression ROC Curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.8276799046927402
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>pretty good, AUC is 82%.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Building-a-logistic-regression-model">Building a logistic regression model<a class="anchor-link" href="#Building-a-logistic-regression-model"> </a></h3><p>In this exercise, you will build a logistic regression model using all features in the diabetes_df dataset. The model will be used to predict the probability of individuals in the test set having a diabetes diagnosis.</p>
<p>The diabetes_df dataset has been split into X_train, X_test, y_train, and y_test, and preloaded for you.</p>
<p>Instructions:</p>
<ul>
<li>Import LogisticRegression.</li>
<li>Instantiate a logistic regression model, logreg.</li>
<li>Fit the model to the training data.</li>
<li>Predict the probabilities of each individual in the test set having a diabetes diagnosis, storing the array of positive probabilities as y_pred_probs.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;diabetes&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="p">[</span><span class="s2">&quot;diabetes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(537, 8) (537,)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Instantiate the model</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># Fit the model</span>
<span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict probabilities</span>
<span class="n">y_pred_probs</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">y_pred_probs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.013280551853663891, 0.12360049836405262, 0.14565956150159862, 0.19015026398045323, 0.2665814559111721, 0.4533458872572005, 0.5045846583954362, 0.5632387659538051, 0.5960905577459668, 0.7999128364794563]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nicely done! Notice how the probability of a diabetes diagnosis for the first 10 individuals in the test set ranges from 0.01 to 0.79. Now let's plot the ROC curve to visualize performance using different thresholds.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-ROC-curve">The ROC curve<a class="anchor-link" href="#The-ROC-curve"> </a></h3><p>Now you have built a logistic regression model for predicting diabetes status, you can plot the ROC curve to visualize how the true positive rate and false positive rate vary as the decision threshold changes.</p>
<p>The test labels, y_test, and the predicted probabilities of the test features belonging to the positive class, y_pred_probs, have been preloaded for you, along with matplotlib.pyplot as plt.</p>
<p>You will create a ROC curve and then interpret the results.</p>
<p>Instructions:</p>
<ul>
<li>Import roc_curve.</li>
<li>Calculate the ROC curve values, using y_test and y_pred_probs, and unpacking the results into fpr, tpr, and thresholds.</li>
<li>Plot true positive rate against false positive rate.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.796523178807947
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>

<span class="c1"># Generate ROC curve values: fpr, tpr, thresholds</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>

<span class="c1"># Plot tpr against fpr</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC Curve for Diabetes Prediction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Question:
Well done on producing the ROC curve for the diabetes prediction model.
But, what does the plot tell you about the model's performance?</p>
<p>Possible Answers:</p>
<ul>
<li><p>The model is about as good as randomly guessing the class of each observation.</p>
</li>
<li><p>The model is much worse than randomly guessing the class of each observation.</p>
</li>
<li><p>The model is much better than randomly guessing the class of each observation.</p>
</li>
<li><p>It is not possible to conclude whether the model performs better or worse than randomly guessing the class of each observation.</p>
<blockquote><p>Ans:The model is much better than randomly guessing the class of each observation.
The ROC curve is above the dotted line, so the model performs better than randomly guessing the class of each observation. (AUC value is 0.796523178807947, which is pretty good)</p>
</blockquote>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ROC-AUC">ROC AUC<a class="anchor-link" href="#ROC-AUC"> </a></h3><p>The ROC curve you plotted in the last exercise looked promising.</p>
<p>Now you will compute the area under the ROC curve, along with the other classification metrics you have used previously.</p>
<p>The confusion_matrix and classification_report functions have been preloaded for you, along with the logreg model you previously built, plus X_train, X_test, y_train, y_test. Also, the model's predicted test set labels are stored as y_pred, and probabilities of test set observations belonging to the positive class stored as y_pred_probs.</p>
<p>A knn model has also been created and the performance metrics printed in the console, so you can compare the roc_auc_score, confusion_matrix, and classification_report between the two models.</p>
<p>Instructions:</p>
<ul>
<li>Import roc_auc_score.</li>
<li>Calculate and print the ROC AUC score, passing the test labels and the predicted positive class probabilities.</li>
<li>Calculate and print the confusion matrix.</li>
<li>Call classification_report().</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="c1"># Calculate roc_auc_score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">))</span>

<span class="c1"># Calculate the confusion matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Calculate the classification report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.796523178807947
[[120  31]
 [ 30  50]]
              precision    recall  f1-score   support

           0       0.80      0.79      0.80       151
           1       0.62      0.62      0.62        80

    accuracy                           0.74       231
   macro avg       0.71      0.71      0.71       231
weighted avg       0.74      0.74      0.74       231

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Did you notice that logistic regression performs better than the KNN model across all the metrics you calculated? A ROC AUC score of 0.7965 means this model is 60% better than a chance model at correctly predicting labels! scikit-learn makes it easy to produce several classification metrics with only a few lines of code.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameter-tuning">Hyperparameter tuning<a class="anchor-link" href="#Hyperparameter-tuning"> </a></h2><h3 id="Hyperparameter-tuning">Hyperparameter tuning<a class="anchor-link" href="#Hyperparameter-tuning"> </a></h3><ul>
<li>Ridge/lasso regression: Choosing <code>alpha</code></li>
<li>KNN: Choosing <code>n_neighbors</code></li>
<li>Hyperparameters: Parameters we specify before fitting the model<ul>
<li>Like alpha and <code>n_neighbors</code></li>
</ul>
</li>
</ul>
<h3 id="Choosing-the-correct-hyperparameters:">Choosing the correct hyperparameters:<a class="anchor-link" href="#Choosing-the-correct-hyperparameters:"> </a></h3><ol>
<li>Try lots of di(erent hyperparameter values</li>
<li>Fit all of them separately</li>
<li>See how well they perform</li>
<li>Choose the best performing values</li>
</ol>
<ul>
<li>This is called hyperparameter tuning</li>
<li>It is essential to use cross-validation to avoid over,2ing to the test set</li>
<li>We can still split the data and perform cross-validation on the training set</li>
<li>We withhold the test set for ,nal evaluation</li>
</ul>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/grid_search.png" alt=""></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sales_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/advertising_and_sales_clean.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">sales_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>


<span class="c1"># Create X from the radio column&#39;s values (.values to make sure they are numpy array)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sales_df</span><span class="p">[[</span><span class="s1">&#39;radio&#39;</span><span class="p">,</span><span class="s1">&#39;social_media&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Create y from the sales column&#39;s values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sales_df</span><span class="p">[</span><span class="s1">&#39;sales&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tv</th>
      <th>radio</th>
      <th>social_media</th>
      <th>influencer</th>
      <th>sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16000.0</td>
      <td>6566.23</td>
      <td>2907.98</td>
      <td>Mega</td>
      <td>54732.76</td>
    </tr>
    <tr>
      <th>1</th>
      <td>13000.0</td>
      <td>9237.76</td>
      <td>2409.57</td>
      <td>Mega</td>
      <td>46677.90</td>
    </tr>
    <tr>
      <th>2</th>
      <td>41000.0</td>
      <td>15886.45</td>
      <td>2913.41</td>
      <td>Mega</td>
      <td>150177.83</td>
    </tr>
    <tr>
      <th>3</th>
      <td>83000.0</td>
      <td>30020.03</td>
      <td>6922.30</td>
      <td>Mega</td>
      <td>298246.34</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15000.0</td>
      <td>8437.41</td>
      <td>1406.00</td>
      <td>Micro</td>
      <td>56594.18</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">KFold</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>  <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                <span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sag&quot;</span><span class="p">,</span> <span class="s2">&quot;lsqr&quot;</span><span class="p">]}</span>

<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span>
<span class="n">ridge_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">ridge_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ridge_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;alpha&#39;: 0.0001, &#39;solver&#39;: &#39;lsqr&#39;} 0.750458310995676
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_score</span> <span class="o">=</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_score</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.7608817222332331
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Limitations of <code>GridSearchCV</code>:</p>
<ul>
<li>3-fold cross-validation, 1 hyperparameter, 10 total values = 30 ,ts</li>
<li>10 fold cross-validation, 3 hyperparameters, 30 total values = 900 ,ts</li>
</ul>
<p>An alternative approach <code>RandomizedSearchCV</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
<span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;lsqr&#39;</span><span class="p">]}</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span>
<span class="n">ridge_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ridge_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ridge_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;solver&#39;: &#39;lsqr&#39;, &#39;alpha&#39;: 0.0001} 0.750458310995676
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_score</span> <span class="o">=</span> <span class="n">ridge_cv</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_score</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.7608817222332331
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameter-tuning-with-GridSearchCV">Hyperparameter tuning with GridSearchCV<a class="anchor-link" href="#Hyperparameter-tuning-with-GridSearchCV"> </a></h3><p>Now you have seen how to perform grid search hyperparameter tuning, you are going to build a lasso regression model with optimal hyperparameters to predict blood glucose levels using the features in the diabetes_df dataset.</p>
<p>X_train, X_test, y_train, and y_test have been preloaded for you. A KFold() object has been created and stored for you as kf, along with a lasso regression model as lasso.</p>
<p>Instructions:</p>
<ul>
<li>Import GridSearchCV.</li>
<li>Set up a parameter grid for "alpha", using np.linspace() to create 20 evenly spaced values ranging from 0.00001 to 1.</li>
<li>Call GridSearchCV(), passing lasso, the parameter grid, and setting cv equal to kf.</li>
<li>Fit the grid search object to the training data to perform a cross-validated grid search.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;glucose&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="p">[</span><span class="s2">&quot;glucose&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(614, 8) (614,)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>


<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#Set up the parameter grid</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.00001</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)}</span>

<span class="c1"># Instantiate lasso_cv</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>
<span class="n">lasso_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lasso</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>

<span class="c1"># Fit to the training data</span>
<span class="n">lasso_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tuned lasso paramaters: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tuned lasso score: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tuned lasso paramaters: {&#39;alpha&#39;: 1e-05}
Tuned lasso score: 0.33078807238121977
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Unfortunately, the best model only has an R-squared score of 0.33, highlighting that using the optimal hyperparameters does not guarantee a high performing model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameter-tuning-with-RandomizedSearchCV">Hyperparameter tuning with RandomizedSearchCV<a class="anchor-link" href="#Hyperparameter-tuning-with-RandomizedSearchCV"> </a></h3><p>As you saw, GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space. In this case, you can use RandomizedSearchCV, which tests a fixed number of hyperparameter settings from specified probability distributions.</p>
<p>Training and test sets from diabetes_df have been pre-loaded for you as X_train. X_test, y_train, and y_test, where the target is "diabetes". A logistic regression model has been created and stored as logreg, as well as a KFold variable stored as kf.</p>
<p>You will define a range of hyperparameters and use RandomizedSearchCV, which has been imported from sklearn.model_selection, to look for optimal hyperparameters from these options.</p>
<p>Instructions:</p>
<ul>
<li>Create params, adding "l1" and "l2" as penalty values, setting C to a range of 50 float values between 0.1 and 1.0, and class_weight to either "balanced" or a dictionary containing 0:0.8, 1:0.2.</li>
<li>Create the Randomized Search CV object, passing the model and the parameters, and setting cv equal to kf.</li>
<li>Fit logreg_cv to the training data.</li>
<li>Print the model's best parameters and accuracy score.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;diabetes&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">diabetes_df</span><span class="p">[</span><span class="s2">&quot;diabetes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(614, 8) (614,)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="c1">#Create the parameter space</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;penalty&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="s2">&quot;l2&quot;</span><span class="p">],</span>
         <span class="s2">&quot;tol&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
         <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
         <span class="s2">&quot;class_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;balanced&quot;</span><span class="p">,</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mf">0.2</span><span class="p">}]}</span>

<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># Instantiate the RandomizedSearchCV object</span>
<span class="n">logreg_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>

<span class="c1"># Fit the data to the model</span>
<span class="n">logreg_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print the tuned parameters and score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tuned Logistic Regression Parameters: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_cv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tuned Logistic Regression Best Accuracy Score: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_cv</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tuned Logistic Regression Parameters: {&#39;tol&#39;: 0.2041612244897959, &#39;penalty&#39;: &#39;l1&#39;, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;C&#39;: 0.7061224489795919}
Tuned Logistic Regression Best Accuracy Score: 0.7378781820605091
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even without exhaustively trying every combination of hyperparameters, the model has an accuracy of over 70% on the test set! So far we have worked with clean datasets; however, in the next chapter, we will discuss the steps required to transform messy data before building supervised learning models.</p>

</div>
</div>
</div>
</div>
 

