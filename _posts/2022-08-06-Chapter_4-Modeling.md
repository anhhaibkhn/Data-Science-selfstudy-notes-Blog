---
keywords: fastai
description: Modeling - Time to bring everything together and build some models! In this last chapter, you will build a base model before tuning some hyperparameters and improving your results with ensembles. You will then get some final tips and tricks to help you compete more efficiently.
title: Winning a Kaggle Competition in Python - Part 4
toc: true
branch: master
badges: true
comments: true
author: Hai Nguyen
categories: [Kaggle, Datacamp, Modeling, Blending, Ensemble, Grid Search, Hyperparamters Tuning, Stacking]
image: images/winning_kaggle_p4.png
hide: false
search_exclude: true
metadata_key1: metadata_value1
metadata_key2: metadata_value2
nb_path: _notebooks/Winning a Kaggle Competition in Python/2022-08-06-Chapter_4 Modeling.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/Winning a Kaggle Competition in Python/2022-08-06-Chapter_4 Modeling.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://github.com/anhhaibkhn/Data-Science-selfstudy-notes-Blog/tree/master/_notebooks/Winning%20a%20Kaggle%20Competition%20in%20Python"><strong>Download Datasets and Presentation slides for this post HERE</strong></a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.expand_frame_repr&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Baseline-model">Baseline model<a class="anchor-link" href="#Baseline-model"> </a></h2><p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/modeling_stage.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/base_line1.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/base_line2.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/base_line3.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/base_line4.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/base_line5.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/intermediate_results.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/corralation_validation_strategy.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Replicate-validation-score">Replicate validation score<a class="anchor-link" href="#Replicate-validation-score"> </a></h3><p>Replicate validation score (Exercise)</p>
<p>You've seen both validation and Public Leaderboard scores in the video. However, the code examples are available only for the test data. To get the validation scores you have to repeat the same process on the holdout set.</p>
<p>Throughout this chapter, you will work with New York City Taxi competition data. The problem is to predict the fare amount for a taxi ride in New York City. The competition metric is the root mean squared error.</p>
<p>The first goal is to evaluate the Baseline model on the validation data. You will replicate the simplest Baseline based on the mean of "fare_amount". Recall that as a validation strategy we used a 30% holdout split with validation_train as train and validation_test as holdout DataFrames. Both of them are available in your workspace.</p>
<p>Instructions:</p>
<ul>
<li>Calculate the mean of "fare_amount" over the whole validation_train DataFrame.</li>
<li>Assign this naive prediction value to all the holdout predictions. Store them in the "pred" column.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">imp</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/taxi_train_chapter_4.csv&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/taxi_test_chapter_4.csv&#39;</span><span class="p">)</span>

<span class="n">validation_train</span><span class="p">,</span> <span class="n">validation_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>



<span class="c1"># Calculate the mean fare_amount on the validation_train data</span>
<span class="n">naive_prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">validation_train</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">])</span>

<span class="c1"># Assign naive prediction to all the holdout observations</span>
<span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">naive_prediction</span>

<span class="c1"># Measure the local RMSE</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">],</span> <span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation RMSE for Baseline I model: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rmse</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Validation RMSE for Baseline I model: 9.986
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's exactly the same number you've seen in the slides, well done! So, to avoid overfitting you should fully replicate your models using the validation data. Go forward to create a couple of other baselines!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Baseline-based-on-the-date">Baseline based on the date<a class="anchor-link" href="#Baseline-based-on-the-date"> </a></h3><p>Baseline based on the date (Exercise)
We've already built 3 different baseline models. To get more practice, let's build a couple more. The first model is based on the grouping variables. It's clear that the ride fare could depend on the part of the day. For example, prices could be higher during the rush hours.</p>
<p>Your goal is to build a baseline model that will assign the average "fare_amount" for the corresponding hour. For now, you will create the model for the whole train data and make predictions for the test dataset.</p>
<p>The train and test DataFrames are available in your workspace. Moreover, the "pickup_datetime" column in both DataFrames is already converted to a datetime object for you.</p>
<p>Instructions:</p>
<ul>
<li>Get the hour from the "pickup_datetime" column for the train and test DataFrames.</li>
<li>Calculate the mean "fare_amount" for each hour on the train data.</li>
<li>Make test predictions using pandas' map() method and the grouping obtained.</li>
<li>Write predictions to the file.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">])</span>

<span class="c1"># Get pickup hour from the pickup_datetime column</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hour_groups</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;hour&#39;</span><span class="p">)[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Make predictions on the test set</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">hour</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">hour_groups</span><span class="p">)</span>

<span class="c1"># Write predictions</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;hour_mean_sub.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">])</span>

<span class="n">validation_train</span><span class="p">,</span> <span class="n">validation_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="n">validation_train</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">validation_train</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pickup_datetime&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>

<span class="n">hour_groups_val</span> <span class="o">=</span> <span class="n">validation_train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;hour&#39;</span><span class="p">)[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Make predictions on the test set</span>
<span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pred2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">validation_test</span><span class="o">.</span><span class="n">hour</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">hour_groups_val</span><span class="p">)</span>

<span class="c1"># Measure the local RMSE</span>
<span class="n">rmse2</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">],</span> <span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pred2&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation RMSE for Baseline II model: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rmse2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Validation RMSE for Baseline II model: 9.985
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Baseline-based-on-the-gradient-boosting">Baseline based on the gradient boosting<a class="anchor-link" href="#Baseline-based-on-the-gradient-boosting"> </a></h3><p>Baseline based on the gradient boosting (Exercise).</p>
<p>Let's build a final baseline based on the Random Forest. You've seen a huge score improvement moving from the grouping baseline to the Gradient Boosting in the video. Now, you will use sklearn's Random Forest to further improve this score.</p>
<p>The goal of this exercise is to take numeric features and train a Random Forest model without any tuning. After that, you could make test predictions and validate the result on the Public Leaderboard. Note that you've already got an "hour" feature which could also be used as an input to the model.</p>
<p>Instructions:</p>
<ul>
<li>dd the "hour" feature to the list of numeric features.</li>
<li>it the RandomForestRegressor on the train data with numeric features and "fare_amount" as a target.</li>
<li>se the trained Random Forest model to make predictions on the test data.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Select only numeric features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pickup_longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;pickup_latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;dropoff_longitude&#39;</span><span class="p">,</span>
            <span class="s1">&#39;dropoff_latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;passenger_count&#39;</span><span class="p">,</span> <span class="s1">&#39;hour&#39;</span><span class="p">]</span>

<span class="c1"># Train a Random Forest model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Write predictions</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;rf_sub.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Select only numeric features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pickup_longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;pickup_latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;dropoff_longitude&#39;</span><span class="p">,</span>
            <span class="s1">&#39;dropoff_latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;passenger_count&#39;</span><span class="p">,</span> <span class="s1">&#39;hour&#39;</span><span class="p">]</span>

<span class="c1"># Train a Random Forest model</span>
<span class="n">rf2</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">rf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">validation_train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">validation_train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pred3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">validation_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Measure the local RMSE</span>
<span class="n">rmse3</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">],</span> <span class="n">validation_test</span><span class="p">[</span><span class="s1">&#39;pred3&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation RMSE for Baseline III model: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rmse3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Validation RMSE for Baseline III model: 5.510
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Congratulations! This final baseline achieves the 1051st place on the Public Leaderboard which is slightly better than the Gradient Boosting from the video. So, now you know how to build fast and simple baseline models to validate your initial pipeline.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameter-tuning">Hyperparameter tuning<a class="anchor-link" href="#Hyperparameter-tuning"> </a></h2><p>Once we have the baseline models results, we can start creating new features.</p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/iterations.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/competition_stategy.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tuning1.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tuning2.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tuning3.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Grid-search">Grid search<a class="anchor-link" href="#Grid-search"> </a></h3><p>Grid search (Exercise):
Recall that we've created a baseline Gradient Boosting model in the previous lesson. Your goal now is to find the best max_depth hyperparameter value for this Gradient Boosting model. This hyperparameter limits the number of nodes in each individual tree. You will be using K-fold cross-validation to measure the local performance of the model for each hyperparameter value.</p>
<p>You're given a function get_cv_score(), which takes the train dataset and dictionary of the model parameters as arguments and returns the overall validation RMSE score over 3-fold cross-validation.</p>
<p>Instructions:</p>
<ul>
<li>Specify the grid for possible max_depth values with 3, 6, 9, 12 and 15.</li>
<li>Pass each hyperparameter candidate in the grid to the model params dictionary.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>

<span class="k">def</span> <span class="nf">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="c1"># Create KFold object</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

    <span class="n">rmse_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Loop through each split</span>
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
        <span class="n">cv_train</span><span class="p">,</span> <span class="n">cv_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
        <span class="c1"># Train a Gradient Boosting model</span>
        <span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cv_train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">cv_train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>
    
        <span class="c1"># Make predictions on the test data</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
    
        <span class="n">fold_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">],</span> <span class="n">pred</span><span class="p">))</span>
        <span class="n">rmse_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fold_score</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_depth_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># For each value in the grid</span>
<span class="k">for</span> <span class="n">max_depth_candidate</span> <span class="ow">in</span> <span class="n">max_depth_grid</span><span class="p">:</span>
    <span class="c1"># Specify parameters for the model</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">max_depth_candidate</span><span class="p">}</span>

    <span class="c1"># Calculate validation score for a particular hyperparameter</span>
    <span class="n">validation_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="c1"># Save the results for each max depth value</span>
    <span class="n">results</span><span class="p">[</span><span class="n">max_depth_candidate</span><span class="p">]</span> <span class="o">=</span> <span class="n">validation_score</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{3: 5.67296, 6: 5.36925, 9: 5.35641, 12: 5.50111, 15: 5.70245}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2D-grid-search">2D grid search<a class="anchor-link" href="#2D-grid-search"> </a></h3><p>2D grid search(Exercise)</p>
<p>The drawback of tuning each hyperparameter independently is a potential dependency between different hyperparameters. The better approach is to try all the possible hyperparameter combinations. However, in such cases, the grid search space is rapidly expanding. For example, if we have 2 parameters with 10 possible values, it will yield 100 experiment runs.</p>
<p>Your goal is to find the best hyperparameter couple of max_depth and subsample for the Gradient Boosting model. subsample is a fraction of observations to be used for fitting the individual trees.</p>
<p>You're given a function get_cv_score(), which takes the train dataset and dictionary of the model parameters as arguments and returns the overall validation RMSE score over 3-fold cross-validation.</p>
<p>Instructions:</p>
<ul>
<li>Specify the grids for possible max_depth and subsample values. For max_depth: 3, 5 and 7. For subsample: 0.8, 0.9 and 1.0.</li>
<li>Apply the product() function from the itertools package to the hyperparameter grids. It returns all possible combinations for these two grids.</li>
<li>Pass each hyperparameters candidate couple to the model params dictionary.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>

<span class="c1"># Hyperparameter grids</span>
<span class="n">max_depth_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span> <span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">subsample_grid</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span> <span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># For each couple in the grid</span>
<span class="k">for</span> <span class="n">max_depth_candidate</span><span class="p">,</span> <span class="n">subsample_candidate</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">max_depth_grid</span><span class="p">,</span> <span class="n">subsample_grid</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">max_depth_candidate</span><span class="p">,</span>
              <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">subsample_candidate</span><span class="p">}</span>
    <span class="n">validation_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="c1"># Save the results for each couple</span>
    <span class="n">results</span><span class="p">[(</span><span class="n">max_depth_candidate</span><span class="p">,</span> <span class="n">subsample_candidate</span><span class="p">)]</span> <span class="o">=</span> <span class="n">validation_score</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{(3, 0.8): 5.65813, (3, 0.9): 5.65228, (3, 1.0): 5.67296, (5, 0.8): 5.34947, (5, 0.9): 5.44506, (5, 1.0): 5.3132, (7, 0.8): 5.38994, (7, 0.9): 5.40631, (7, 1.0): 5.3591}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># sort by value</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[((5, 1.0), 5.3132),
 ((5, 0.8), 5.34947),
 ((7, 1.0), 5.3591),
 ((7, 0.8), 5.38994),
 ((7, 0.9), 5.40631),
 ((5, 0.9), 5.44506),
 ((3, 0.9), 5.65228),
 ((3, 0.8), 5.65813),
 ((3, 1.0), 5.67296)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-ensembling">Model ensembling<a class="anchor-link" href="#Model-ensembling"> </a></h2><p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/ensemble1.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/ensemble2.png" alt=""></p>
<p>Blending appoach is to find an average of multiple models predictions.</p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/ensemble3.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/ensemble4.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/ensemble5.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/stacking.png" alt=""></p>
<p>To demonstrate the above 6 steps:</p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/stacking2.png" alt=""></p>
<p>Train 3 models A, B and C on part 1 set</p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/stacking3.png" alt=""></p>
<p>Then use 3 models A, B and C to predict on both the train_validation (part 2) and test sets.</p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/stacking4.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/stacking5.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/stacking6.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-blending">Model blending<a class="anchor-link" href="#Model-blending"> </a></h3><p>Model blending (Exercise)
You will start creating model ensembles with a blending technique.</p>
<p>Your goal is to train 2 different models on the New York City Taxi competition data. Make predictions on the test data and then blend them using a simple arithmetic mean.</p>
<p>The train and test DataFrames are already available in your workspace. features is a list of columns to be used for training and it is also available in your workspace. The target variable name is "fare_amount".</p>
<p>Instructions:</p>
<ul>
<li>Train a Gradient Boosting model on the train data using features list, and the "fare_amount" column as a target variable.</li>
<li>Train a Random Forest model in the same manner.</li>
<li>Make predictions on the test data using both Gradient Boosting and Random Forest models.</li>
<li>Find the average of both models predictions.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/taxi_train_distance.csv&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./datasets/taxi_test_distance.csv&#39;</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pickup_longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;pickup_latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;dropoff_longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;dropoff_latitude&#39;</span><span class="p">,</span> 
            <span class="s1">&#39;passenger_count&#39;</span><span class="p">,</span> <span class="s1">&#39;distance_km&#39;</span><span class="p">,</span> <span class="s1">&#39;hour&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>            
<span class="c1"># Train a Gradient Boosting model</span>
<span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Train a Random Forest model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;rf_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Find mean of model predictions</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;blend&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">]</span> <span class="o">+</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;rf_pred&#39;</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">,</span> <span class="s1">&#39;rf_pred&#39;</span><span class="p">,</span> <span class="s1">&#39;blend&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    gb_pred  rf_pred     blend
0  9.661374    9.313  9.487187
1  9.304288    8.238  8.771144
2  5.795140    4.835  5.315070
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Blending allows you to get additional score improvements almost for free just by averaging multiple models predictions. Now, let's explore model stacking!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-stacking-I">Model stacking I<a class="anchor-link" href="#Model-stacking-I"> </a></h3><p>Model stacking I (Exercise):
Now it's time for stacking. To implement the stacking approach, you will follow the 6 steps we've discussed in the previous video:</p>
<ol>
<li>Split train data into two parts</li>
<li>Train multiple models on Part 1</li>
<li>Make predictions on Part 2</li>
<li>Make predictions on the test data</li>
<li>Train a new model on Part 2 using predictions as features</li>
<li>Make predictions on the test data using the 2nd level model</li>
</ol>
<p><em>train</em> and <em>test</em> DataFrames are already available in your workspace. features is a list of columns to be used for training on the Part 1 data and it is also available in your workspace. Target variable name is "fare_amount".</p>
<p>Instructions:</p>
<ul>
<li>Split the train DataFrame into two equal parts: part_1 and part_2. Use the train_test_split() function with test_size equal to 0.5.</li>
<li>Train Gradient Boosting and Random Forest models on the part_1 data.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Split train data into two parts</span>
<span class="n">part_1</span><span class="p">,</span> <span class="n">part_2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Train a Gradient Boosting model on Part 1</span>
<span class="n">gb2</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">part_1</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">part_1</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Train a Random Forest model on Part 1</span>
<span class="n">rf2</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">part_1</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">part_1</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Make Gradient Boosting and Random Forest predictions on the part_2 data.</li>
<li>Make Gradient Boosting and Random Forest predictions on the test data.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">part_2</span> <span class="o">=</span> <span class="n">part_2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">part_2</span><span class="p">[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gb2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">part_2</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">part_2</span><span class="p">[</span><span class="s1">&#39;rf_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">part_2</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="c1"># Make predictions on the test data</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gb2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;rf_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-stacking-II">Model stacking II<a class="anchor-link" href="#Model-stacking-II"> </a></h3><p>OK, what you've done so far in the stacking implementation:</p>
<ol>
<li>Split train data into two parts</li>
<li>Train multiple models on Part 1</li>
<li>Make predictions on Part 2</li>
<li>Make predictions on the test data</li>
</ol>
<p>Now, your goal is to create a second level model using predictions from steps 3 and 4 as features. So, this model is trained on Part 2 data and then you can make stacking predictions on the test data.</p>
<p>part_2 and test DataFrames are already available in your workspace. Gradient Boosting and Random Forest predictions are stored in these DataFrames under the names "gb_pred" and "rf_pred", respectively.</p>
<p>Instructions:</p>
<ul>
<li>Train a Linear Regression model on the Part 2 data using Gradient Boosting and Random Forest models predictions as features.</li>
<li>Make predictions on the test data using Gradient Boosting and Random Forest models predictions as features.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Create linear regression model without the intercept</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Train 2nd level model on the Part 2 data</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">part_2</span><span class="p">[[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">,</span> <span class="s1">&#39;rf_pred&#39;</span><span class="p">]],</span> <span class="n">part_2</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>

<span class="c1"># Make stacking predictions on the test data</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;stacking&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s1">&#39;gb_pred&#39;</span><span class="p">,</span> <span class="s1">&#39;rf_pred&#39;</span><span class="p">]])</span>

<span class="c1"># Look at the model coefficients</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.14050404 0.86266408]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Congratulations, now your toolbox contains ensembling techniques! Usually, the 2nd level model is some simple model like Linear or Logistic Regressions. Also, note that you were not using intercept in the Linear Regression just to combine pure model predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Final-tips">Final tips<a class="anchor-link" href="#Final-tips"> </a></h2><p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tip1.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tip2.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tip3.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tip4.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/tip5.png" alt=""></p>
<h3 id="Testing-Kaggle-forum-ideas">Testing Kaggle forum ideas<a class="anchor-link" href="#Testing-Kaggle-forum-ideas"> </a></h3><p>Testing Kaggle forum ideas(Exercise)
Unfortunately, not all the Forum posts and Kernels are necessarily useful for your model. So instead of blindly incorporating ideas into your pipeline, you should test them first.</p>
<p>You're given a function get_cv_score(), which takes a train dataset as an argument and returns the overall validation root mean squared error over 3-fold cross-validation. The train DataFrame is already available in your workspace.</p>
<p>You should try different suggestions from the Kaggle Forum and check whether they improve your validation score.</p>
<ul>
<li>Suggestion 1: the passenger_count feature is useless. Let's see! Drop this feature and compare the scores.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="k">def</span> <span class="nf">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pickup_longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;pickup_latitude&#39;</span><span class="p">,</span>
            <span class="s1">&#39;dropoff_longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;dropoff_latitude&#39;</span><span class="p">,</span>
            <span class="s1">&#39;passenger_count&#39;</span><span class="p">,</span> <span class="s1">&#39;distance_km&#39;</span><span class="p">,</span> <span class="s1">&#39;hour&#39;</span><span class="p">,</span> <span class="s1">&#39;weird_feature&#39;</span><span class="p">]</span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
    
    <span class="c1"># Create KFold object</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

    <span class="n">rmse_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Loop through each split</span>
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
        <span class="n">cv_train</span><span class="p">,</span> <span class="n">cv_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
        <span class="c1"># Train a Gradient Boosting model</span>
        <span class="n">gb</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cv_train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">cv_train</span><span class="o">.</span><span class="n">fare_amount</span><span class="p">)</span>
    
        <span class="c1"># Make predictions on the test data</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
    
        <span class="n">fold_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">cv_test</span><span class="p">[</span><span class="s1">&#39;fare_amount&#39;</span><span class="p">],</span> <span class="n">pred</span><span class="p">))</span>
        <span class="n">rmse_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fold_score</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_scores</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_train_1</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;passenger_count&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compare validation scores</span>
<span class="n">initial_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">new_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">new_train_1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initial score is </span><span class="si">{}</span><span class="s1"> and the new score is </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">initial_score</span><span class="p">,</span> <span class="n">new_score</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Initial score is 6.49932 and the new score is 6.42315
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This first suggestion worked.</p>
<ul>
<li>Suggestion 2: Sum of pickup_latitude and distance_km is a good feature. Let's try it!</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_train_2</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Find sum of pickup latitude and ride distance</span>
<span class="n">new_train_2</span><span class="p">[</span><span class="s1">&#39;weird_feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_train_2</span><span class="p">[</span><span class="s1">&#39;pickup_latitude&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">new_train_2</span><span class="p">[</span><span class="s1">&#39;distance_km&#39;</span><span class="p">]</span>

<span class="c1"># Compare validation scores</span>
<span class="n">initial_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">new_score</span> <span class="o">=</span> <span class="n">get_cv_score</span><span class="p">(</span><span class="n">new_train_2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initial score is </span><span class="si">{}</span><span class="s1"> and the new score is </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">initial_score</span><span class="p">,</span> <span class="n">new_score</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Initial score is 6.49932 and the new score is 6.50495
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Be aware that not all the ideas shared publicly could work for you! In this particular case, dropping the "passenger_count" feature helped, while finding the sum of pickup latitude and ride distance did not. The last action you perform in any Kaggle competition is selecting final submissions. Go on to practice it!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Select-final-submissions">Select final submissions<a class="anchor-link" href="#Select-final-submissions"> </a></h3><p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/submision_choice.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Final-thoughts">Final thoughts<a class="anchor-link" href="#Final-thoughts"> </a></h3><p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/summary1.png" alt=""></p>
<p><img src="/Data-Science-selfstudy-notes-Blog/images/copied_from_nb/./images/summary2.png" alt=""></p>

</div>
</div>
</div>
</div>
 

